#+PROPERTY: header-args:sqlite :db data.db
* Netz Ã¼ber Scalpel
** Mit Functoren, Applicative und Monaden:
http://hs.eraveline.eu/posts/scalpel.html

https://www.reddit.com/r/haskell/comments/5eu4h6/question_scraping_multiple_urls_with_scalpel/

http://adit.io/posts/2012-03-10-building_a_concurrent_web_scraper_with_haskell.htmlhttp://adit.io/posts/2012-03-10-building_a_concurrent_web_scraper_with_haskell.html

https://github.com/min-nguyen/league-scraper

https://github.com/haasn/hsbooru

https://github.com/grafted-in/web-scraping-engine

* SQL
** Graph-based url scraping
#+begin_src sqlite
SELECT url_id, url, 0 as depth FROM url WHERE url like '%index.html%';
#+end_src

#+begin_src sqlite
SELECT source, target, 1 as depth FROM url_scraped
LEFT JOIN url ON source = url_id WHERE url like '%index.html%';
#+end_src

#+begin_src sqlite
WITH RECURSIVE url_graph AS (
     SELECT source, target, 1 as depth FROM url_scraped
     LEFT JOIN url ON source = url_id WHERE url like '%index.html%'
     UNION ALL
     SELECT s.source, s.target, url_graph.depth + 1 FROM url_scraped AS s
     INNER JOIN url_graph ON s.source = url_graph.target)
     SELECT count(*) FROM url_graph WHERE depth = 2;
#+end_src
