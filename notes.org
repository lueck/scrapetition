
* Netz Ã¼ber Scalpel
** Mit Functoren, Applicative und Monaden:
http://hs.eraveline.eu/posts/scalpel.html

https://www.reddit.com/r/haskell/comments/5eu4h6/question_scraping_multiple_urls_with_scalpel/

http://adit.io/posts/2012-03-10-building_a_concurrent_web_scraper_with_haskell.htmlhttp://adit.io/posts/2012-03-10-building_a_concurrent_web_scraper_with_haskell.html

https://github.com/min-nguyen/league-scraper

https://github.com/haasn/hsbooru

https://github.com/grafted-in/web-scraping-engine


* Trying SQL

#+begin_src sqlite :db /tmp/vatican.db
SELECT url_id, url, 0 as depth FROM url WHERE url = 'http://www.vatican.va';
#+end_src

#+RESULTS:
| 1 | http://www.vatican.va | 0 |

#+begin_src sqlite :db /tmp/vatican.db
SELECT source, target, 1 as depth FROM url_scraped
LEFT JOIN url ON source = url_id WHERE url = 'http://www.vatican.va';
#+end_src

#+RESULTS:
| 1 | 2 | 1 |

#+begin_src sqlite :db /tmp/vatican.db
WITH RECURSIVE url_graph AS (
     SELECT source, target, 1 as depth FROM url_scraped
     LEFT JOIN url ON source = url_id WHERE url = 'http://www.vatican.va'
     UNION ALL
     SELECT s.source, s.target, url_graph.depth + 1 FROM url_scraped AS s
     INNER JOIN url_graph ON s.source = url_graph.target)
     SELECT count(*) FROM url_graph WHERE depth = 2;
#+end_src

#+RESULTS:
